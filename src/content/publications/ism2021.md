---
title: "Combining Global and Local Attention with Positional Encoding for Video Summarization"
authors:
  - Evlampios Apostolidis
  - Georgios Balaouras
  - Vasileios Mezaris
  - Ioannis Patras
author_notes:
  - "Equal contribution"
  - "Equal contribution"
date: 2021-12-01
doi: "10.1109/ISM52913.2021.00045"
publication_types: ["1"]
publication: "IEEE Int. Symposium on Multimedia (ISM) 2021"
publication_short: "ISM2021"
abstract: "This paper presents a new method for supervised video summarization. To overcome drawbacks of existing RNN-based summarization architectures, that relate to the modeling of long-range frames' dependencies and the ability to parallelize the training process, the developed model relies on the use of self-attention mechanisms to estimate the importance of video frames. Contrary to previous attention-based summarization approaches that model the frames' dependencies by observing the entire frame sequence, our method combines global and local multi-head attention mechanisms to discover different modelings of the frames' dependencies at different levels of granularity. Moreover, the utilized attention mechanisms integrate a component that encodes the temporal position of video frames - this is of major importance when producing a video summary. Experiments on two datasets (SumMe and TVSum) demonstrate the effectiveness of the proposed model compared to existing attention-based methods, and its competitiveness against other state-of-the-art supervised summarization approaches. An ablation study that focuses on our main proposed components, namely the use of global and local multi-head attention mechanisms in collaboration with an absolute positional encoding component, shows their relative contributions to the overall summarization performance."
summary: "A supervised self-attention-based method for automated video summarization."
tags:
  - video summarization
  - self-attention
  - multi-head attention
  - positional encoding
  - supervised learning
featured: true
url_pdf: "/media/files/ism2021_preprint.pdf"
url_code: "https://github.com/e-apostolidis/PGL-SUM"
url_project: "http://multimedia2.iti.gr/videosummarization/service/start.html"
url_slides: "/media/slides/ism2021_slides.pptx"
url_video: "https://www.youtube.com/watch?v=LbjPLJzeNII"
featuredImage: "/publications/ism2021/featured.png"
---

This paper presents a new method for supervised video summarization. To overcome drawbacks of existing RNN-based summarization architectures, that relate to the modeling of long-range frames' dependencies and the ability to parallelize the training process, the developed model relies on the use of self-attention mechanisms to estimate the importance of video frames.

## Method

Contrary to previous attention-based summarization approaches that model the frames' dependencies by observing the entire frame sequence, our method combines global and local multi-head attention mechanisms to discover different modelings of the frames' dependencies at different levels of granularity. Moreover, the utilized attention mechanisms integrate a component that encodes the temporal position of video frames - this is of major importance when producing a video summary.

## Results

Experiments on two datasets (SumMe and TVSum) demonstrate the effectiveness of the proposed model compared to existing attention-based methods, and its competitiveness against other state-of-the-art supervised summarization approaches. An ablation study that focuses on our main proposed components, namely the use of global and local multi-head attention mechanisms in collaboration with an absolute positional encoding component, shows their relative contributions to the overall summarization performance.
