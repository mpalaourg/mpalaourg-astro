---
title: "Explaining video summarization based on the focus of attention"
authors:
  - Evlampios Apostolidis
  - Georgios Balaouras
  - Vasileios Mezaris
  - Ioannis Patras
author_notes:
  - "Equal contribution"
  - "Equal contribution"
date: 2022-12-06
doi: "10.1109/ISM55400.2022.00029"
publication_types: ["1"]
publication: "IEEE Int. Symposium on Multimedia (ISM) 2022"
publication_short: "ISM2022"
abstract: "In this paper we propose a method for explaining video summarization. We start by formulating the problem as the creation of an explanation mask which indicates the parts of the video that influenced the most the estimates of a video summarization network, about the frames' importance. Then, we explain how the typical analysis pipeline of attention-based networks for video summarization can be used to define explanation signals, and we examine various attention-based signals that have been studied as explanations in the NLP domain. We evaluate the performance of these signals by investigating the video summarization network's input-output relationship according to different replacement functions, and utilizing measures that quantify the capability of explanations to spot the most and least influential parts of a video. We run experiments using an attention-based network (CA-SUM) and two datasets (SumMe and TVSum) for video summarization. Our evaluations indicate the advanced performance of explanations formed using the inherent attention weights, and demonstrate the ability of our method to explain the video summarization results using clues about the focus of the attention mechanism."
summary: "A method for explaining video summarization."
tags:
  - explainable ai
  - video summarization
  - self-attention
  - concentrated attention
  - ca-sum
  - evaluation metrics
featured: true
url_pdf: "/media/files/ism2022_preprint.pdf"
url_code: "https://github.com/e-apostolidis/XAI-SUM"
featuredImage: "/publications/ism2022/featured.png"
---

In this paper we propose a method for explaining video summarization.

## Problem Formulation

We start by formulating the problem as the creation of an explanation mask which indicates the parts of the video that influenced the most the estimates of a video summarization network, about the frames' importance.

## Methodology

We explain how the typical analysis pipeline of attention-based networks for video summarization can be used to define explanation signals, and we examine various attention-based signals that have been studied as explanations in the NLP domain.

## Evaluation

We evaluate the performance of these signals by investigating the video summarization network's input-output relationship according to different replacement functions, and utilizing measures that quantify the capability of explanations to spot the most and least influential parts of a video. We run experiments using an attention-based network (CA-SUM) and two datasets (SumMe and TVSum) for video summarization. Our evaluations indicate the advanced performance of explanations formed using the inherent attention weights, and demonstrate the ability of our method to explain the video summarization results using clues about the focus of the attention mechanism.
